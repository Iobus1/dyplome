import os
import aiohttp
from dotenv import load_dotenv
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from database import (
    init_db,
    search_knowledge_base,
    save_to_db,
    FREQUENT_QUESTIONS,
)

load_dotenv("keys.env")

BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")
HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")

if not BOT_TOKEN:
    raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è TELEGRAM_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ keys.env")
if not HF_TOKEN:
    raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è HUGGINGFACE_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ keys.env")

HF_MODEL_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3"
HF_HEADERS = {
    "Authorization": f"Bearer {HF_TOKEN}",
    "Content-Type": "application/json",
}

LEARNING_COMMANDS = [
    ["üìö –ù–∞–π—Ç–∏ –º–∞—Ç–µ—Ä–∏–∞–ª", "üß† –ó–∞–ø–æ–º–Ω–∏—Ç—å"],
    ["üîç –ü–æ–≤—Ç–æ—Ä–∏—Ç—å", "‚ùì –ü–æ–º–æ—â—å"],
    ["‚¨ÖÔ∏è –í –º–µ–Ω—é"],
]

# –®–∞–±–ª–æ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
TEMPLATES = {
    "–ø—Ä–∏–≤–µ—Ç": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
    "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
    "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å": "–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –ö–∞–∫–æ–π —É –≤–∞—Å –≤–æ–ø—Ä–æ—Å?",
    "–¥–∞": "–û—Ç–ª–∏—á–Ω–æ!",
    "–Ω–µ—Ç": "–ü–æ–Ω—è—Ç–Ω–æ.",
    "–ø–æ–∫–∞": "–î–æ —Å–∫–æ—Ä–æ–≥–æ! –•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è!",
    "—Å–ø–∞—Å–∏–±–æ": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞!",
    "–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é": "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é!",
    "–∫–∞–∫ –¥–µ–ª–∞": "–£ –º–µ–Ω—è –≤—Å—ë —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
}

HELP_TEXT = (
    "üÜò <b>–ü–æ–º–æ—â—å –ø–æ –±–æ—Ç—É</b>:\n\n"
    "üìö –ù–∞–∂–º–∏—Ç–µ <b>¬´–ù–∞–π—Ç–∏ –º–∞—Ç–µ—Ä–∏–∞–ª¬ª</b>, —á—Ç–æ–±—ã –∑–∞–¥–∞—Ç—å —Ç–µ–º—É –∏ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.\n"
    "üß† –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –ò–ò –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –≤–∞—à—É –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∫–Ω–æ–ø–∫–æ–π <b>¬´–ó–∞–ø–æ–º–Ω–∏—Ç—å¬ª</b>.\n"
    "üîç <b>–ü–æ–≤—Ç–æ—Ä–∏—Ç—å</b> ‚Äî –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª.\n"
    "‚ùì <b>–ü–æ–º–æ—â—å</b> ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ.\n"
    "‚¨ÖÔ∏è <b>–í –º–µ–Ω—é</b> ‚Äî –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é.\n\n"
    "–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –µ–≥–æ."
)

async def query_llm(prompt: str, max_tokens: int = 150) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ Mistral-7B-Instruct –Ω–∞ Hugging Face."""
    payload = {
        "inputs": prompt,
        "parameters": {
            "temperature": 0.5,
            "max_new_tokens": max_tokens,
            "return_full_text": False,
        },
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                HF_MODEL_URL, headers=HF_HEADERS, json=payload, timeout=90
            ) as resp:
                if resp.status != 200:
                    error_text = await resp.text()
                    return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Hugging Face API: {error_text}"

                data = await resp.json()
                return data[0]["generated_text"].strip()
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM: {e}"

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –º–µ–Ω—é."""
    await update.message.reply_text(
        "<b>ü§ñ –£—á–µ–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ 2025</b>\n\n"
        "–ó–∞–¥–∞–π—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å –ø–æ —É—á–µ–±–Ω–æ–π —Ç–µ–º–µ, –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ –∏–∑ –º–µ–Ω—é.",
        parse_mode="HTML",
        reply_markup=ReplyKeyboardMarkup(LEARNING_COMMANDS, resize_keyboard=True),
    )
    context.user_data.clear()

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–í –º–µ–Ω—é"
    if text == "‚¨ÖÔ∏è –í –º–µ–Ω—é":
        await cmd_start(update, context)
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ü–æ–º–æ—â—å"
    if text == "‚ùì –ü–æ–º–æ—â—å":
        await update.message.reply_text(HELP_TEXT, parse_mode="HTML")
        return

    # –ï—Å–ª–∏ –æ–∂–∏–¥–∞–µ–º —Ç–µ–º—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
    if context.user_data.get("awaiting_topic"):
        context.user_data.pop("awaiting_topic")
        topic = text

        # –ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ
        local_answer = search_knowledge_base(topic)
        if local_answer:
            await update.message.reply_text(
                f"üìò <b>–û—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:</b>\n\n{local_answer}", parse_mode="HTML"
            )
            context.user_data["last_response"] = (topic, local_answer)
            return

        await update.message.reply_text("‚åõ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ, —è –∏—â—É –æ—Ç–≤–µ—Ç...")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —á—ë—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏
        llm_prompt = f"–ü–æ—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ —Ä–∞–∑–¥–µ–ª—ã –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –ø–æ —Ç–µ–º–µ: \"{topic}\"."

        llm_answer = await query_llm(llm_prompt)

        # –û—á–∏—â–∞–µ–º –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        llm_answer = llm_answer.lstrip(",. \n")

        await update.message.reply_text(
            f"üß† <b>–û—Ç–≤–µ—Ç –ò–ò:</b>\n\n{llm_answer}",
            parse_mode="HTML",
            reply_markup=ReplyKeyboardMarkup(
                [["üß† –ó–∞–ø–æ–º–Ω–∏—Ç—å", "‚¨ÖÔ∏è –í –º–µ–Ω—é"]], resize_keyboard=True, one_time_keyboard=True
            ),
        )
        context.user_data["last_response"] = (topic, llm_answer)
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —à–∞–±–ª–æ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    if text.lower() in TEMPLATES:
        await update.message.reply_text(TEMPLATES[text.lower()])
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –±–∞–∑—ã
    for key, answer in FREQUENT_QUESTIONS.items():
        if key in text.lower():
            await update.message.reply_text(
                f"üìò <b>–û—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:</b>\n\n{answer}", parse_mode="HTML"
            )
            return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ù–∞–π—Ç–∏ –º–∞—Ç–µ—Ä–∏–∞–ª" ‚Äî –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≤–æ–ø—Ä–æ—Å—É –æ —Ç–µ–º–µ
    if text == "üìö –ù–∞–π—Ç–∏ –º–∞—Ç–µ—Ä–∏–∞–ª":
        context.user_data["awaiting_topic"] = True
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞:")
        return

    # –ï—Å–ª–∏ –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç
    if not text:
        await update.message.reply_text(
            "‚ö†Ô∏è –Ø –Ω–µ —É–≤–∏–¥–µ–ª –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ."
        )
        return

    # –ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ
    local_answer = search_knowledge_base(text)
    if local_answer:
        await update.message.reply_text(
            f"üìò <b>–û—Ç–≤–µ—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:</b>\n\n{local_answer}", parse_mode="HTML"
        )
        return

    # –°–æ–æ–±—â–∞–µ–º –æ –Ω–∞—á–∞–ª–µ –ø–æ–∏—Å–∫–∞
    await update.message.reply_text("‚åõ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ, —è –∏—â—É –æ—Ç–≤–µ—Ç...")

    llm_prompt = f"–ü–æ—è—Å–Ω–∏ –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞: {text}"

    llm_answer = await query_llm(llm_prompt)
    llm_answer = llm_answer.lstrip(",. \n")

    await update.message.reply_text(
        f"üß† <b>–û—Ç–≤–µ—Ç –ò–ò:</b>\n\n{llm_answer}",
        parse_mode="HTML",
        reply_markup=ReplyKeyboardMarkup(
            [["üß† –ó–∞–ø–æ–º–Ω–∏—Ç—å", "‚¨ÖÔ∏è –í –º–µ–Ω—é"]], resize_keyboard=True, one_time_keyboard=True
        ),
    )
    context.user_data["last_response"] = (text, llm_answer)

async def save_response(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if "last_response" not in context.user_data:
        await update.message.reply_text("‚ùå –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
        return

    question, answer = context.user_data["last_response"]
    try:
        save_to_db(question, answer)
        await update.message.reply_text("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π!",
                                        reply_markup=ReplyKeyboardMarkup(LEARNING_COMMANDS, resize_keyboard=True))
    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å: {e}")

def main() -> None:
    init_db()

    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(MessageHandler(filters.Regex("^üß† –ó–∞–ø–æ–º–Ω–∏—Ç—å$"), save_response))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    print("‚úÖ –£—á–µ–±–Ω—ã–π –±–æ—Ç –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è...")
    app.run_polling()

if __name__ == "__main__":
    main()
